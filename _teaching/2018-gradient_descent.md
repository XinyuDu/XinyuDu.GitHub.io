---
title: "梯度下降法"
collection: teaching
type: "神经网络教程-1"
permalink: /teaching/2018-gradient-descent
venue: "杜新宇,中科院北京纳米能源与系统研究所"
date: 2018-07-12
location: "中国, 北京"
---

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

# 1. 介绍

梯度下降法(gradient descent)是用来求函数$$f(x_1,x_2,\underbrace{\ldots}_{\rm ldots} ,x_n) = x_1^2 + x_2^2 + \underbrace{\cdots}_{\rm cdots} + x_n^2$$最小值的方法，更准确的说是求**使得函数取得最小值**。